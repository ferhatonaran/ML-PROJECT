{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv(r'.\\data\\train.csv')\n",
    "testDf =  pd.read_csv(r'.\\data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDf = trainDf[(trainDf != 0).all(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(965282, 6)\n",
      "(4620309, 5)\n"
     ]
    }
   ],
   "source": [
    "print(trainDf.shape)\n",
    "print(testDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainNIR = trainDf[\"NIR\"]\n",
    "trainRED = trainDf[\"Red\"]\n",
    "trainGreen = trainDf[\"Green\"]\n",
    "\n",
    "trainDf[\"NDVI\"] =( trainNIR-trainRED) / (trainNIR+trainRED)\n",
    "trainDf[\"NDWI\"] = (trainGreen-trainNIR) / (trainGreen+ trainNIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Code</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>NIR</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1997</td>\n",
       "      <td>1982</td>\n",
       "      <td>1860</td>\n",
       "      <td>3672</td>\n",
       "      <td>0.327549</td>\n",
       "      <td>-0.298903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1950</td>\n",
       "      <td>1906</td>\n",
       "      <td>1776</td>\n",
       "      <td>3335</td>\n",
       "      <td>0.305028</td>\n",
       "      <td>-0.272658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1933</td>\n",
       "      <td>1886</td>\n",
       "      <td>1742</td>\n",
       "      <td>3390</td>\n",
       "      <td>0.321122</td>\n",
       "      <td>-0.285064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2162</td>\n",
       "      <td>2035</td>\n",
       "      <td>2173</td>\n",
       "      <td>3605</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>-0.278369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2159</td>\n",
       "      <td>2165</td>\n",
       "      <td>2112</td>\n",
       "      <td>3611</td>\n",
       "      <td>0.261926</td>\n",
       "      <td>-0.250346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966990</th>\n",
       "      <td>966990</td>\n",
       "      <td>80</td>\n",
       "      <td>2355</td>\n",
       "      <td>2127</td>\n",
       "      <td>1986</td>\n",
       "      <td>1917</td>\n",
       "      <td>-0.017679</td>\n",
       "      <td>0.051929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966991</th>\n",
       "      <td>966991</td>\n",
       "      <td>80</td>\n",
       "      <td>2382</td>\n",
       "      <td>2115</td>\n",
       "      <td>2001</td>\n",
       "      <td>1934</td>\n",
       "      <td>-0.017027</td>\n",
       "      <td>0.044702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966992</th>\n",
       "      <td>966992</td>\n",
       "      <td>80</td>\n",
       "      <td>2398</td>\n",
       "      <td>2146</td>\n",
       "      <td>2011</td>\n",
       "      <td>1965</td>\n",
       "      <td>-0.011569</td>\n",
       "      <td>0.044028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966993</th>\n",
       "      <td>966993</td>\n",
       "      <td>80</td>\n",
       "      <td>2346</td>\n",
       "      <td>2105</td>\n",
       "      <td>2004</td>\n",
       "      <td>1917</td>\n",
       "      <td>-0.022188</td>\n",
       "      <td>0.046743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966994</th>\n",
       "      <td>966994</td>\n",
       "      <td>80</td>\n",
       "      <td>2329</td>\n",
       "      <td>2065</td>\n",
       "      <td>1985</td>\n",
       "      <td>1882</td>\n",
       "      <td>-0.026636</td>\n",
       "      <td>0.046364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965282 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Code  Blue  Green   Red   NIR      NDVI      NDWI\n",
       "1            1    10  1997   1982  1860  3672  0.327549 -0.298903\n",
       "2            2    10  1950   1906  1776  3335  0.305028 -0.272658\n",
       "3            3    10  1933   1886  1742  3390  0.321122 -0.285064\n",
       "4            4    10  2162   2035  2173  3605  0.247837 -0.278369\n",
       "5            5    10  2159   2165  2112  3611  0.261926 -0.250346\n",
       "...        ...   ...   ...    ...   ...   ...       ...       ...\n",
       "966990  966990    80  2355   2127  1986  1917 -0.017679  0.051929\n",
       "966991  966991    80  2382   2115  2001  1934 -0.017027  0.044702\n",
       "966992  966992    80  2398   2146  2011  1965 -0.011569  0.044028\n",
       "966993  966993    80  2346   2105  2004  1917 -0.022188  0.046743\n",
       "966994  966994    80  2329   2065  1985  1882 -0.026636  0.046364\n",
       "\n",
       "[965282 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testNIR = testDf[\"NIR\"]\n",
    "testRED = testDf[\"Red\"]\n",
    "testGreen = testDf[\"Green\"]\n",
    "\n",
    "testDf[\"NDVI\"] =( testNIR-testRED) / (testNIR+testRED)\n",
    "testDf[\"NDWI\"] = (testGreen-testNIR) / (testGreen+ testNIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>NIR</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1938</td>\n",
       "      <td>1880</td>\n",
       "      <td>1683</td>\n",
       "      <td>3362</td>\n",
       "      <td>0.332805</td>\n",
       "      <td>-0.282717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>1874</td>\n",
       "      <td>1661</td>\n",
       "      <td>3388</td>\n",
       "      <td>0.342048</td>\n",
       "      <td>-0.287723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1959</td>\n",
       "      <td>1876</td>\n",
       "      <td>1690</td>\n",
       "      <td>3354</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>-0.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1943</td>\n",
       "      <td>1873</td>\n",
       "      <td>1696</td>\n",
       "      <td>3305</td>\n",
       "      <td>0.321736</td>\n",
       "      <td>-0.276555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620304</th>\n",
       "      <td>4620304</td>\n",
       "      <td>1880</td>\n",
       "      <td>1590</td>\n",
       "      <td>1366</td>\n",
       "      <td>1235</td>\n",
       "      <td>-0.050365</td>\n",
       "      <td>0.125664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620305</th>\n",
       "      <td>4620305</td>\n",
       "      <td>1891</td>\n",
       "      <td>1594</td>\n",
       "      <td>1369</td>\n",
       "      <td>1237</td>\n",
       "      <td>-0.050652</td>\n",
       "      <td>0.126104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620306</th>\n",
       "      <td>4620306</td>\n",
       "      <td>1879</td>\n",
       "      <td>1591</td>\n",
       "      <td>1375</td>\n",
       "      <td>1242</td>\n",
       "      <td>-0.050822</td>\n",
       "      <td>0.123191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620307</th>\n",
       "      <td>4620307</td>\n",
       "      <td>1879</td>\n",
       "      <td>1584</td>\n",
       "      <td>1378</td>\n",
       "      <td>1242</td>\n",
       "      <td>-0.051908</td>\n",
       "      <td>0.121019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620308</th>\n",
       "      <td>4620308</td>\n",
       "      <td>1881</td>\n",
       "      <td>1589</td>\n",
       "      <td>1376</td>\n",
       "      <td>1241</td>\n",
       "      <td>-0.051586</td>\n",
       "      <td>0.122968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4620309 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  Blue  Green   Red   NIR      NDVI      NDWI\n",
       "0              0     0      0     0     0       NaN       NaN\n",
       "1              1  1938   1880  1683  3362  0.332805 -0.282717\n",
       "2              2  1943   1874  1661  3388  0.342048 -0.287723\n",
       "3              3  1959   1876  1690  3354  0.329897 -0.282600\n",
       "4              4  1943   1873  1696  3305  0.321736 -0.276555\n",
       "...          ...   ...    ...   ...   ...       ...       ...\n",
       "4620304  4620304  1880   1590  1366  1235 -0.050365  0.125664\n",
       "4620305  4620305  1891   1594  1369  1237 -0.050652  0.126104\n",
       "4620306  4620306  1879   1591  1375  1242 -0.050822  0.123191\n",
       "4620307  4620307  1879   1584  1378  1242 -0.051908  0.121019\n",
       "4620308  4620308  1881   1589  1376  1241 -0.051586  0.122968\n",
       "\n",
       "[4620309 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = trainDf[['Blue','Green','Red','NIR','NDVI','NDWI']]\n",
    "y = trainDf[['Code']]\n",
    "testDf = testDf.fillna(0)\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KNN with 3 7 and 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(testDf[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_knn3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(testDf[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_knn7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors=13)\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(testDf[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_knn13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "X_test.fillna(0)\n",
    "rf_model.fit(X_train[['Blue','Green','Red','NIR','NDVI','NDWI']], y_train)\n",
    "y_pred = rf_model.predict(X_test[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "y_pred\n",
    "\n",
    "X_teest=testDf\n",
    "X_teest.fillna(0)\n",
    "y_pred = rf_model.predict(X_teest[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_randomforest.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf = HistGradientBoostingClassifier(max_iter=200)\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(testDf[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_histgradient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(testDf[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_gradient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(testDf[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_extratree.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(testDf[['Blue','Green','Red','NIR','NDVI','NDWI']])\n",
    "\n",
    "dataframe = pd.DataFrame(y_pred)\n",
    "dataframe.rename(columns={dataframe.columns[0]: 'Code'}, inplace=True)\n",
    "dataframe.index.name = 'ID'\n",
    "dataframe.to_csv('ferhat_adaboost.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(KNN) algorithm with different values of k (3, 7, and 13) and analyzed the results. We then turned to the random forest algorithm and observed that it provided the highest score (0.35) among all the algorithms we tested. Additionally, we attempted to use decision trees, but were unable to achieve better results than those obtained with random forest. Furthermore, we noticed that support vector machines (SVMs) do not perform well on large datasets due to computational complexity.K-nearest neighbors (KNN) is a supervised learning algorithm that can be used for classification or regression tasks. The algorithm works by identifying the k-number of training samples that are closest to a new sample and then classifying the new sample based on the majority class of the k-nearest samples. The value of k can be adjusted to improve the performance of the algorithm. Random forest is an ensemble learning method that constructs multiple decision trees and combines their predictions through majority voting (for classification) or averaging (for regression). It is known for its high accuracy and ability to handle large datasets with many features. Decision tree is a type of supervised learning algorithm that can be used for both classification and regression tasks. It works by recursively partitioning the feature space into regions, each corresponding to a particular class or value. The algorithm starts at the root node of the tree and recursively partition the feature space by selecting the feature that maximizes the information gain at each level. Support Vector Machines (SVMs) are a set of supervised learning methods that can be used for classification and regression. The main idea behind SVMs is to find the hyperplane in a high-dimensional feature space that maximally separates the different classes. However, SVMs can be computationally expensive and may not scale well for large datasets, as it is a complex algorithm that tries to find the optimal boundary that maximizes the margin .\n",
    "I aimed to investigate the use of various machine learning algorithms for land use and land cover classification. We applied k-nearest neighbors (KNN), random forest, decision trees, and support vector machines (SVMs) to a given dataset and compared their performance.\n",
    "The results showed that among the algorithms tested, random forest yielded the highest score of 0.35. Additionally, we found that KNN performed well with small values of k, but larger values did not result in a significant improvement. On the other hand, decision trees failed to provide better results than random forest. Furthermore, we observed that SVMs did not scale well on large datasets due to their computational complexity.\n",
    "KNN is a simple yet effective algorithm for classification and regression tasks. It is easy to implement and does not require much computational power. However, it may not perform well on large datasets with many features. Random forest is a powerful algorithm that can handle large datasets and high dimensionality. Additionally, it is robust to noise and outliers. However, it can be computationally expensive and may require more memory. Decision trees are simple to understand and interpret, but they are prone to overfitting and may not be as accurate as other algorithms. SVMs are known for their high accuracy and ability to handle non-linearly separable data. However, they can be computationally expensive and may not scale well on large datasets.\n",
    "In conclusion, this study demonstrates that machine learning algorithms can be effectively used for land use and land cover classification. Among the algorithms tested, random forest proved to be the most effective, while KNN and decision trees performed similarly but not as well as random forest. However, SVMs did not perform well on large datasets due to computational complexity. Therefore, it is important to consider the size of the dataset and computational resources when choosing a machine learning algorithm for land use and land cover classification.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
